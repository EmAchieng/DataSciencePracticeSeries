{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of SIT_W4D1_LC3_Training_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmAchieng/DataSciencePracticeSeries/blob/master/NeuralNetworks_LC3_Training_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIS49soByJyL"
      },
      "source": [
        "<center><a target=\"_blank\" href=\"http://www.propulsion.academy\"><img src=\"https://drive.google.com/uc?id=1McNxpNrSwfqu1w-QtlOmPSmfULvkkMQV\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center> <h1> Live Coding - Training ANNs </h1> </center>\n",
        "\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>Propulsion Academy, 2020</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc7QWSVYyJyM"
      },
      "source": [
        "# Live Coding - Training ANNs\n",
        "\n",
        "This notebook has been adapted from the tutorial of [hands on Machine learning, chapter 11](https://github.com/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE4hwI3yJyN"
      },
      "source": [
        "## Setup\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "871nhzIHyJyO",
        "outputId": "dfd4308a-45d8-4e2c-a99d-dcd19d63fb62"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0CRpS1byJyV"
      },
      "source": [
        "## Vanishing gradient problem\n",
        "\n",
        "### Example: LeakyRelu activation function and he_normal weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kaBNu8_zJvH"
      },
      "source": [
        "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zYcYt92zFH8",
        "outputId": "d23777f1-127c-4a67-d272-5f586067ad29"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX-8baBmzN1d"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.LeakyReLU(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtmKNhfSzPxj"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3juR1d36zRzV",
        "outputId": "071c4d93-cbf3-4700-c16b-9a3b6de9dad6"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=5,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656.8245 - accuracy:  - ETA: 0s - - ETA: 0s - loss: 0.7955 - accuracy: 0.73\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7902\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8064\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWF6reSOyzIp"
      },
      "source": [
        "### Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOz82JwNy0KI"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3jDrQFlzV5Y",
        "outputId": "f2314fad-6aad-4211-8b17-05cf89ccbea4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 300)               1200      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               30100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 271,346\n",
            "Trainable params: 268,978\n",
            "Non-trainable params: 2,368\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFKgdsqzYH3",
        "outputId": "b7a71414-97c1-4847-b0cd-16f2705c3ba1"
      },
      "source": [
        "bn1 = model.layers[1]\n",
        "[(var.name, var.trainable) for var in bn1.variables]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('batch_normalization/gamma:0', True),\n",
              " ('batch_normalization/beta:0', True),\n",
              " ('batch_normalization/moving_mean:0', False),\n",
              " ('batch_normalization/moving_variance:0', False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65efTrphzY79",
        "outputId": "2358313d-d9e6-4f45-8252-04c35d558618"
      },
      "source": [
        "bn1.updates"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-3f3161b80a85>:1: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVnsDSIbzcCW"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYSdXsW6zdqe",
        "outputId": "2d03c353-f3cf-4047-a55b-34a4e4f19958"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=5,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.8293 - accuracy: 0.7221 - val_loss: 0.5539 - val_accuracy: 0.8160 - - ETA: 0s - loss: 0.8372 - accuracy: \n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5703 - accuracy: 0.8035 - val_loss: 0.4792 - val_accuracy: 0.8378\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5161 - accuracy: 0.8213 - val_loss: 0.4424 - val_accuracy: 0.8492\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4789 - accuracy: 0.8316 - val_loss: 0.4212 - val_accuracy: 0.8570\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4548 - accuracy: 0.8406 - val_loss: 0.4050 - val_accuracy: 0.8614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dInVu9Nwzf5B"
      },
      "source": [
        "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTJdIrcGzgWI"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(300, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(100, use_bias=False),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Activation(\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkgFQcpLzjZ8"
      },
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Yp9G9ozk7m",
        "outputId": "5ca19d3c-5218-4dab-de43-86d8e7662158"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=5,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 1.0346 - accuracy: 0.6739 - val_loss: 0.6680 - val_accuracy: 0.7886\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6757 - accuracy: 0.7818 - val_loss: 0.5537 - val_accuracy: 0.8212\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5961 - accuracy: 0.8021 - val_loss: 0.4996 - val_accuracy: 0.8352curacy: 0.79 - ETA: 2s - l -\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5456 - accuracy: 0.8176 - val_loss: 0.4655 - val_accuracy: 0.8462\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5140 - accuracy: 0.8249 - val_loss: 0.4420 - val_accuracy: 0.8506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeDnkikmz_LK"
      },
      "source": [
        "## Optimizers\n",
        "### Gradient descent optimizers (SGD, Adam, Adagrad, RMSProp)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEtnMW3P0CFD"
      },
      "source": [
        "#examples of different optimizers\n",
        "#optimizer = keras.optimizers.Adagrad(lr=0.001)\n",
        "\n",
        "#optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "#optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sudotqww0C-3"
      },
      "source": [
        "### Optimizing learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKVnvb_t0E-m"
      },
      "source": [
        "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6MbsXaV1NGg"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ33mNAE1NkF",
        "outputId": "2c5b4bd4-d087-4a9a-f412-65485ad595af"
      },
      "source": [
        "n_epochs = 5\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5835 - accuracy: 0.7973 - val_loss: 0.4623 - val_accuracy: 0.8438\n",
            "Epoch 2/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4487 - accuracy: 0.8396 - val_loss: 0.4157 - val_accuracy: 0.8584\n",
            "Epoch 3/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4190 - accuracy: 0.8518 - val_loss: 0.4665 - val_accuracy: 0.8236\n",
            "Epoch 4/5\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4017 - accuracy: 0.8575 - val_loss: 0.3964 - val_accuracy: 0.8626\n",
            "Epoch 5/5\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3904 - accuracy: 0.8623 - val_loss: 0.3859 - val_accuracy: 0.8660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9KSQwx81OGE",
        "outputId": "0c675e17-28ab-45a9-d70e-afacc40f0e4a"
      },
      "source": [
        "learning_rate = 0.01\n",
        "decay = 1e-4\n",
        "batch_size = 32\n",
        "n_steps_per_epoch = len(X_train) // batch_size\n",
        "epochs = np.arange(n_epochs)\n",
        "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
        "\n",
        "plt.plot(epochs, lrs,  \"o-\")\n",
        "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Power Scheduling\", fontsize=14)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1JKpZc-46lq"
      },
      "source": [
        "## Learning Rate Scheduling\n",
        "\n",
        "The default learning rate schedule is to use a constant learning rate to update network weights for each training epoch. However, adapting the learning rate for your stochastic gradient descent optimization procedure can increase performance and reduce training time.\n",
        "\n",
        "It provides the benefit of making large changes at the beginning of the training procedure when larger learning rate values are used, and decreasing the learning rate such that a smaller rate and therefore smaller training updates are made to weights later in the training procedure.\n",
        "\n",
        "Keras has multiple learning rate schedule APIs:\n",
        "- ExponentialDecay\n",
        "- PiecewiseConstantDecay\n",
        "- PolynomialDecay\n",
        "- InverseTimeDecay\n",
        "\n",
        "Further info on keras learning rate schedules: https://keras.io/api/optimizers/learning_rate_schedules/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHYY5zRA0YMO"
      },
      "source": [
        "### Learning Rate Scheduling: 1cycle Scheduling\n",
        "\n",
        "The motivation behind a cycling schedule rate is to oscillate the learning rate towards higher learning rate to help to get out of saddle points. If saddle point is elaborate plateau, the lower learning rates might not be able get gradient out of saddle point. (Conventionally , the learning rate is decreased as the learning starts converging with time)\n",
        "\n",
        "The cycle is number of iterations where we go from lower bound learning rate to higher bound and back to lower bound. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qEl7KCO2oHY"
      },
      "source": [
        "class OneCycleScheduler(keras.callbacks.Callback):\n",
        "    def __init__(self, iterations, max_rate, start_rate=None,\n",
        "                 last_iterations=None, last_rate=None):\n",
        "        self.iterations = iterations\n",
        "        self.max_rate = max_rate\n",
        "        self.start_rate = start_rate or max_rate / 10\n",
        "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
        "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
        "        self.last_rate = last_rate or self.start_rate / 1000\n",
        "        self.iteration = 0\n",
        "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
        "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
        "                / (iter2 - iter1) + rate1)\n",
        "    def on_batch_begin(self, batch, logs):\n",
        "        if self.iteration < self.half_iteration:\n",
        "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
        "        elif self.iteration < 2 * self.half_iteration:\n",
        "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
        "                                     self.max_rate, self.start_rate)\n",
        "        else:\n",
        "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
        "                                     self.start_rate, self.last_rate)\n",
        "            rate = max(rate, self.last_rate)\n",
        "        self.iteration += 1\n",
        "        K.set_value(self.model.optimizer.lr, rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWzelKOj2qWi"
      },
      "source": [
        "n_epochs = 25\n",
        "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpiAbwdYjwNN",
        "outputId": "fa239bce-64f3-4339-b682-f4b2a3d4f694"
      },
      "source": [
        "from keras import backend as K\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs=n_epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[onecycle])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3768 - accuracy: 0.8665 - val_loss: 0.4212 - val_accuracy: 0.8495\n",
            "Epoch 2/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3750 - accuracy: 0.8656 - val_loss: 0.4132 - val_accuracy: 0.8548\n",
            "Epoch 3/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3714 - accuracy: 0.8677 - val_loss: 0.5027 - val_accuracy: 0.8093\n",
            "Epoch 4/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3675 - accuracy: 0.8692 - val_loss: 0.4067 - val_accuracy: 0.8572\n",
            "Epoch 5/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3637 - accuracy: 0.8704 - val_loss: 0.4095 - val_accuracy: 0.8537\n",
            "Epoch 6/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3555 - accuracy: 0.8722 - val_loss: 0.3980 - val_accuracy: 0.8597\n",
            "Epoch 7/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3502 - accuracy: 0.8754 - val_loss: 0.4022 - val_accuracy: 0.8575\n",
            "Epoch 8/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3445 - accuracy: 0.8761 - val_loss: 0.4324 - val_accuracy: 0.8412\n",
            "Epoch 9/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3377 - accuracy: 0.8793 - val_loss: 0.4138 - val_accuracy: 0.8477\n",
            "Epoch 10/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3322 - accuracy: 0.8805 - val_loss: 0.4051 - val_accuracy: 0.8519\n",
            "Epoch 11/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3263 - accuracy: 0.8817 - val_loss: 0.3792 - val_accuracy: 0.8649\n",
            "Epoch 12/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3174 - accuracy: 0.8855 - val_loss: 0.3702 - val_accuracy: 0.8658\n",
            "Epoch 13/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.8881 - val_loss: 0.3701 - val_accuracy: 0.8663\n",
            "Epoch 14/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3003 - accuracy: 0.8919 - val_loss: 0.3872 - val_accuracy: 0.8614\n",
            "Epoch 15/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2925 - accuracy: 0.8939 - val_loss: 0.3634 - val_accuracy: 0.8682 0.2923 - accuracy: 0.89\n",
            "Epoch 16/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2870 - accuracy: 0.8966 - val_loss: 0.3532 - val_accuracy: 0.8702\n",
            "Epoch 17/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2816 - accuracy: 0.8988 - val_loss: 0.3743 - val_accuracy: 0.8644\n",
            "Epoch 18/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2766 - accuracy: 0.9015 - val_loss: 0.3553 - val_accuracy: 0.8723\n",
            "Epoch 19/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2727 - accuracy: 0.9031 - val_loss: 0.3505 - val_accuracy: 0.8745\n",
            "Epoch 20/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2690 - accuracy: 0.9047 - val_loss: 0.3523 - val_accuracy: 0.8709\n",
            "Epoch 21/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2655 - accuracy: 0.9047 - val_loss: 0.3475 - val_accuracy: 0.8767\n",
            "Epoch 22/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2631 - accuracy: 0.9057 - val_loss: 0.3464 - val_accuracy: 0.8755- accuracy: 0. - E\n",
            "Epoch 23/25\n",
            "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2609 - accuracy: 0.9070 - val_loss: 0.3464 - val_accuracy: 0.8755\n",
            "Epoch 24/25\n",
            "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2594 - accuracy: 0.9084 - val_loss: 0.3466 - val_accuracy: 0.8768\n",
            "Epoch 25/25\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2587 - accuracy: 0.9082 - val_loss: 0.3459 - val_accuracy: 0.8755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCBa-TrE0r3Q"
      },
      "source": [
        "## Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIc16DoUMa-0"
      },
      "source": [
        "### $\\ell_1$ and $\\ell_2$ regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL6SUUMp0hK0"
      },
      "source": [
        "layer = keras.layers.Dense(100, activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
        "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCAH-sBd00eb",
        "outputId": "360d473a-da93-41b8-a286-216554612c2c"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(100, activation=\"elu\",\n",
        "                       kernel_initializer=\"he_normal\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "    keras.layers.Dense(10, activation=\"softmax\",\n",
        "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 1.5494 - accuracy: 0.7775 - val_loss: 1.0217 - val_accuracy: 0.7630\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 0.9076 - accuracy: 0.7928 - val_loss: 0.8534 - val_accuracy: 0.8176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfAhMuJf02yA",
        "outputId": "68cab405-7377-4e45-adb4-6c93255ba7de"
      },
      "source": [
        "from functools import partial\n",
        "\n",
        "RegularizedDense = partial(keras.layers.Dense,\n",
        "                           activation=\"elu\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    RegularizedDense(300),\n",
        "    RegularizedDense(100),\n",
        "    RegularizedDense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 6s 4ms/step - loss: 1.6293 - accuracy: 0.7792 - val_loss: 1.0124 - val_accuracy: 0.7664\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 5s 3ms/step - loss: 0.9057 - accuracy: 0.7962 - val_loss: 0.8513 - val_accuracy: 0.8200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOCfQzRg0u-6"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRyIdCj30wnf",
        "outputId": "2a8f78e5-939e-4255-9b26-f6df9c7d14d8"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
        "    keras.layers.Dropout(rate=0.2),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "n_epochs = 2\n",
        "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5822 - accuracy: 0.7888 - val_loss: 0.4178 - val_accuracy: 0.8420\n",
            "Epoch 2/2\n",
            "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4550 - accuracy: 0.8317 - val_loss: 0.3668 - val_accuracy: 0.8662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXbO3x8u-Xoe"
      },
      "source": [
        "## Hyperparameters\n",
        "### hyperparameter optimization: n_hidden, n_neurons, learning_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap4eR2cCCDno",
        "outputId": "320eefc8-4a9a-48d5-8921-23528afd910e"
      },
      "source": [
        "!pip install keras-tuner\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import kerastuner as kt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (1.0.1)\n",
            "Requirement already satisfied: tqdm in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (4.47.0)\n",
            "Requirement already satisfied: numpy in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.23.1)\n",
            "Requirement already satisfied: scipy in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (1.5.0)\n",
            "Requirement already satisfied: tabulate in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied: future in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: colorama in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.4.3)\n",
            "Requirement already satisfied: terminaltables in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: requests in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from keras-tuner) (2.24.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->keras-tuner) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/shirleyxueyinghe/opt/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (1.25.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDrV70FACS8l"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijIZSY3tCOrI"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKD4FntJCYBI"
      },
      "source": [
        "train_images = train_images.reshape(len(train_images), 28, 28, 1)\n",
        "test_images = test_images.reshape(len(test_images), 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn1Isw_1DGA_"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9k_ZcDmCaiI"
      },
      "source": [
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "    \n",
        "    # Tune the number of units in the first Dense layer\n",
        "    # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
        "    model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "    # Tune the learning rate for the optimizer \n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "  \n",
        "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
        "                metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r2aZygxEtRf"
      },
      "source": [
        "\n",
        "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - RandomSearch, Hyperband, BayesianOptimization, and Sklearn. In this tutorial, you use the Hyperband tuner.\n",
        "\n",
        "To instantiate the Hyperband tuner, you must specify the hypermodel, the objective to optimize and the maximum number of epochs to train (max_epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsvz7gLoErHU"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_accuracy', \n",
        "                     max_epochs = 10,\n",
        "                     factor = 3,\n",
        "                     directory = 'my_dir',\n",
        "                     project_name = 'intro_to_kt')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CEX5CQBE_Ob"
      },
      "source": [
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "    def on_train_end(*args, **kwargs):\n",
        "        IPython.display.clear_output(wait = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUDJL6zDFEhC"
      },
      "source": [
        "Run the hyperparameter search. The arguments for the search method are the same as those used for tf.keras.model.fit in addition to the callback above.\n",
        "\n",
        "\n",
        "More info on kerastuner: https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWC2HB-QIl00"
      },
      "source": [
        "import IPython\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X_XUE4uCmxR",
        "outputId": "49d95b6f-a507-4303-a38f-d1730029444e"
      },
      "source": [
        "tuner.search(x=train_images, y=train_labels,epochs=5,batch_size=64,validation_data=(test_images, test_labels),  callbacks = [ClearTrainingOutput()])\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Trial ID: 90cd695f0c0d6202b160ff3d86daf35d</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.8641999959945679</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-tuner/bracket: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-tuner/epochs: 10</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-units: 288</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 192 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6g9Xc4JE58o",
        "outputId": "4719032e-4c47-41e4-8d09-6ff4f911987d"
      },
      "source": [
        "best_hps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<kerastuner.engine.hyperparameters.HyperParameters at 0x1467d5490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cclX2uoq-dcU"
      },
      "source": [
        "### Tensorboard\n",
        "\n",
        "\n",
        "More info on TensorBoard: TensorFlow's visualization toolkit\n",
        "https://www.tensorflow.org/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_y5wDMN-ezW",
        "outputId": "ef918f44-42b9-48d1-fe57-794013587fb9"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC6rwzW7I-BX"
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BBiWxgcJGDC"
      },
      "source": [
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAIDkKR3JRNf"
      },
      "source": [
        "#1. Experiment setup and the HParams experiment summary\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "    hp.hparams_config(\n",
        "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOytd86JJWUm"
      },
      "source": [
        "#2. Adapt TensorFlow runs to log hyperparameters and metrics\n",
        "def train_test_model(hparams):\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax),\n",
        "  ])\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "    \n",
        "    model.fit(X_train, y_train, epochs=1) # Run with 1 epoch to speed things up for demo purposes\n",
        "    _, accuracy = model.evaluate(X_test, y_test)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Y-Z8dJJWxf"
      },
      "source": [
        "#For each run, log an hparams summary with the hyperparameters and final accuracy:\n",
        "\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "    with tf.summary.create_file_writer(run_dir).as_default():\n",
        "        hp.hparams(hparams)  # record the values used in this trial\n",
        "        accuracy = train_test_model(hparams)\n",
        "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpLc-fSaJ_Tj"
      },
      "source": [
        "Start runs and log them all under one parent directory\n",
        "\n",
        "\n",
        "You can now try multiple experiments, training each one with a different set of hyperparameters.\n",
        "\n",
        "For simplicity, use a grid search: try all combinations of the discrete parameters and just the lower and upper bounds of the real-valued parameter. For more complex scenarios, it might be more effective to choose each hyperparameter value randomly (this is called a random search). There are more advanced methods that can be used.\n",
        "\n",
        "Run a few experiments, which will take a few minutes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7II6X3S3JXEQ",
        "outputId": "fc89efa2-b652-4778-ce4e-8c8b706e1626"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'adam'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.6363 - accuracy: 0.06 - ETA: 1s - loss: 1.9124 - accuracy: 0.36 - ETA: 2s - loss: 1.7363 - accuracy: 0.41 - ETA: 2s - loss: 1.6560 - accuracy: 0.44 - ETA: 2s - loss: 1.5045 - accuracy: 0.49 - ETA: 2s - loss: 1.3858 - accuracy: 0.53 - ETA: 2s - loss: 1.2913 - accuracy: 0.56 - ETA: 1s - loss: 1.2272 - accuracy: 0.58 - ETA: 1s - loss: 1.1805 - accuracy: 0.60 - ETA: 1s - loss: 1.1371 - accuracy: 0.61 - ETA: 1s - loss: 1.0936 - accuracy: 0.63 - ETA: 1s - loss: 1.0462 - accuracy: 0.64 - ETA: 1s - loss: 1.0200 - accuracy: 0.65 - ETA: 1s - loss: 0.9875 - accuracy: 0.66 - ETA: 1s - loss: 0.9685 - accuracy: 0.66 - ETA: 1s - loss: 0.9455 - accuracy: 0.67 - ETA: 1s - loss: 0.9220 - accuracy: 0.68 - ETA: 1s - loss: 0.9107 - accuracy: 0.68 - ETA: 1s - loss: 0.8945 - accuracy: 0.69 - ETA: 0s - loss: 0.8768 - accuracy: 0.70 - ETA: 0s - loss: 0.8629 - accuracy: 0.70 - ETA: 0s - loss: 0.8472 - accuracy: 0.70 - ETA: 0s - loss: 0.8341 - accuracy: 0.71 - ETA: 0s - loss: 0.8268 - accuracy: 0.71 - ETA: 0s - loss: 0.8167 - accuracy: 0.71 - ETA: 0s - loss: 0.8097 - accuracy: 0.72 - ETA: 0s - loss: 0.8030 - accuracy: 0.72 - ETA: 0s - loss: 0.7933 - accuracy: 0.72 - ETA: 0s - loss: 0.7858 - accuracy: 0.72 - ETA: 0s - loss: 0.7788 - accuracy: 0.73 - ETA: 0s - loss: 0.7724 - accuracy: 0.73 - ETA: 0s - loss: 0.7662 - accuracy: 0.73 - ETA: 0s - loss: 0.7596 - accuracy: 0.73 - ETA: 0s - loss: 0.7532 - accuracy: 0.74 - ETA: 0s - loss: 0.7473 - accuracy: 0.74 - ETA: 0s - loss: 0.7413 - accuracy: 0.74 - ETA: 0s - loss: 0.7365 - accuracy: 0.74 - 2s 1ms/step - loss: 0.7339 - accuracy: 0.7463\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.6324 - accuracy: 0.75 - ETA: 0s - loss: 0.4795 - accuracy: 0.83 - ETA: 0s - loss: 0.4948 - accuracy: 0.82 - ETA: 0s - loss: 0.5059 - accuracy: 0.82 - ETA: 0s - loss: 0.5097 - accuracy: 0.82 - ETA: 0s - loss: 0.5069 - accuracy: 0.82 - ETA: 0s - loss: 0.5081 - accuracy: 0.82 - 0s 1ms/step - loss: 0.5062 - accuracy: 0.8216\n",
            "--- Starting trial: run-1\n",
            "{'num_units': 16, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.4575 - accuracy: 0.06 - ETA: 1s - loss: 2.1599 - accuracy: 0.23 - ETA: 2s - loss: 2.1229 - accuracy: 0.24 - ETA: 3s - loss: 2.1195 - accuracy: 0.24 - ETA: 4s - loss: 2.1056 - accuracy: 0.25 - ETA: 4s - loss: 2.0639 - accuracy: 0.27 - ETA: 4s - loss: 2.0331 - accuracy: 0.28 - ETA: 4s - loss: 2.0133 - accuracy: 0.30 - ETA: 4s - loss: 1.9534 - accuracy: 0.32 - ETA: 3s - loss: 1.8881 - accuracy: 0.35 - ETA: 3s - loss: 1.8616 - accuracy: 0.36 - ETA: 4s - loss: 1.8522 - accuracy: 0.36 - ETA: 4s - loss: 1.8336 - accuracy: 0.37 - ETA: 3s - loss: 1.7812 - accuracy: 0.39 - ETA: 3s - loss: 1.7118 - accuracy: 0.41 - ETA: 2s - loss: 1.6525 - accuracy: 0.43 - ETA: 2s - loss: 1.6059 - accuracy: 0.45 - ETA: 2s - loss: 1.5610 - accuracy: 0.47 - ETA: 2s - loss: 1.5282 - accuracy: 0.48 - ETA: 2s - loss: 1.4889 - accuracy: 0.49 - ETA: 1s - loss: 1.4588 - accuracy: 0.50 - ETA: 1s - loss: 1.4285 - accuracy: 0.51 - ETA: 1s - loss: 1.3981 - accuracy: 0.52 - ETA: 1s - loss: 1.3711 - accuracy: 0.53 - ETA: 1s - loss: 1.3464 - accuracy: 0.54 - ETA: 1s - loss: 1.3210 - accuracy: 0.54 - ETA: 1s - loss: 1.2985 - accuracy: 0.55 - ETA: 1s - loss: 1.2758 - accuracy: 0.56 - ETA: 1s - loss: 1.2566 - accuracy: 0.57 - ETA: 0s - loss: 1.2393 - accuracy: 0.57 - ETA: 0s - loss: 1.2250 - accuracy: 0.57 - ETA: 0s - loss: 1.2080 - accuracy: 0.58 - ETA: 0s - loss: 1.1963 - accuracy: 0.59 - ETA: 0s - loss: 1.1826 - accuracy: 0.59 - ETA: 0s - loss: 1.1686 - accuracy: 0.60 - ETA: 0s - loss: 1.1524 - accuracy: 0.60 - ETA: 0s - loss: 1.1373 - accuracy: 0.61 - ETA: 0s - loss: 1.1246 - accuracy: 0.61 - ETA: 0s - loss: 1.1141 - accuracy: 0.61 - ETA: 0s - loss: 1.1043 - accuracy: 0.62 - ETA: 0s - loss: 1.0945 - accuracy: 0.62 - ETA: 0s - loss: 1.0840 - accuracy: 0.62 - ETA: 0s - loss: 1.0759 - accuracy: 0.63 - 2s 1ms/step - loss: 1.0719 - accuracy: 0.6326\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.65 - ETA: 0s - loss: 0.6530 - accuracy: 0.78 - ETA: 0s - loss: 0.6532 - accuracy: 0.78 - ETA: 0s - loss: 0.6705 - accuracy: 0.77 - ETA: 0s - loss: 0.6784 - accuracy: 0.77 - ETA: 0s - loss: 0.6781 - accuracy: 0.77 - ETA: 0s - loss: 0.6779 - accuracy: 0.77 - ETA: 0s - loss: 0.6761 - accuracy: 0.77 - ETA: 0s - loss: 0.6744 - accuracy: 0.77 - 0s 1ms/step - loss: 0.6739 - accuracy: 0.7752\n",
            "--- Starting trial: run-2\n",
            "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.7702 - accuracy: 0.06 - ETA: 1s - loss: 2.0299 - accuracy: 0.30 - ETA: 1s - loss: 1.9300 - accuracy: 0.33 - ETA: 2s - loss: 1.8699 - accuracy: 0.34 - ETA: 2s - loss: 1.7634 - accuracy: 0.37 - ETA: 1s - loss: 1.6422 - accuracy: 0.41 - ETA: 1s - loss: 1.5656 - accuracy: 0.44 - ETA: 1s - loss: 1.4820 - accuracy: 0.47 - ETA: 1s - loss: 1.4427 - accuracy: 0.48 - ETA: 1s - loss: 1.3909 - accuracy: 0.50 - ETA: 1s - loss: 1.3562 - accuracy: 0.51 - ETA: 1s - loss: 1.3173 - accuracy: 0.52 - ETA: 1s - loss: 1.2790 - accuracy: 0.54 - ETA: 1s - loss: 1.2550 - accuracy: 0.55 - ETA: 1s - loss: 1.2278 - accuracy: 0.56 - ETA: 1s - loss: 1.2055 - accuracy: 0.56 - ETA: 1s - loss: 1.1862 - accuracy: 0.57 - ETA: 1s - loss: 1.1644 - accuracy: 0.58 - ETA: 1s - loss: 1.1479 - accuracy: 0.59 - ETA: 1s - loss: 1.1320 - accuracy: 0.59 - ETA: 1s - loss: 1.1160 - accuracy: 0.60 - ETA: 1s - loss: 1.1007 - accuracy: 0.60 - ETA: 0s - loss: 1.0816 - accuracy: 0.61 - ETA: 0s - loss: 1.0703 - accuracy: 0.61 - ETA: 0s - loss: 1.0597 - accuracy: 0.62 - ETA: 0s - loss: 1.0487 - accuracy: 0.62 - ETA: 0s - loss: 1.0404 - accuracy: 0.62 - ETA: 0s - loss: 1.0356 - accuracy: 0.62 - ETA: 0s - loss: 1.0247 - accuracy: 0.63 - ETA: 0s - loss: 1.0168 - accuracy: 0.63 - ETA: 0s - loss: 1.0098 - accuracy: 0.63 - ETA: 0s - loss: 0.9973 - accuracy: 0.64 - ETA: 0s - loss: 0.9890 - accuracy: 0.64 - ETA: 0s - loss: 0.9815 - accuracy: 0.64 - ETA: 0s - loss: 0.9736 - accuracy: 0.65 - ETA: 0s - loss: 0.9672 - accuracy: 0.65 - ETA: 0s - loss: 0.9605 - accuracy: 0.65 - ETA: 0s - loss: 0.9537 - accuracy: 0.65 - ETA: 0s - loss: 0.9481 - accuracy: 0.65 - ETA: 0s - loss: 0.9421 - accuracy: 0.66 - ETA: 0s - loss: 0.9367 - accuracy: 0.66 - 2s 1ms/step - loss: 0.9331 - accuracy: 0.6635\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.6611 - accuracy: 0.75 - ETA: 0s - loss: 0.5389 - accuracy: 0.81 - ETA: 0s - loss: 0.5520 - accuracy: 0.81 - ETA: 0s - loss: 0.5626 - accuracy: 0.80 - ETA: 0s - loss: 0.5602 - accuracy: 0.81 - 0s 696us/step - loss: 0.5578 - accuracy: 0.8120\n",
            "--- Starting trial: run-3\n",
            "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.6899 - accuracy: 0.09 - ETA: 1s - loss: 2.2280 - accuracy: 0.18 - ETA: 1s - loss: 2.1477 - accuracy: 0.22 - ETA: 1s - loss: 2.0706 - accuracy: 0.26 - ETA: 1s - loss: 1.9636 - accuracy: 0.31 - ETA: 1s - loss: 1.8571 - accuracy: 0.35 - ETA: 1s - loss: 1.7918 - accuracy: 0.37 - ETA: 1s - loss: 1.7532 - accuracy: 0.39 - ETA: 1s - loss: 1.6851 - accuracy: 0.41 - ETA: 1s - loss: 1.6406 - accuracy: 0.42 - ETA: 1s - loss: 1.5998 - accuracy: 0.44 - ETA: 1s - loss: 1.5584 - accuracy: 0.45 - ETA: 1s - loss: 1.5205 - accuracy: 0.46 - ETA: 1s - loss: 1.4899 - accuracy: 0.48 - ETA: 1s - loss: 1.4629 - accuracy: 0.48 - ETA: 1s - loss: 1.4415 - accuracy: 0.49 - ETA: 1s - loss: 1.4214 - accuracy: 0.50 - ETA: 0s - loss: 1.3965 - accuracy: 0.51 - ETA: 0s - loss: 1.3789 - accuracy: 0.51 - ETA: 0s - loss: 1.3647 - accuracy: 0.52 - ETA: 0s - loss: 1.3454 - accuracy: 0.53 - ETA: 0s - loss: 1.3355 - accuracy: 0.53 - ETA: 0s - loss: 1.3230 - accuracy: 0.53 - ETA: 0s - loss: 1.3111 - accuracy: 0.54 - ETA: 0s - loss: 1.3003 - accuracy: 0.54 - ETA: 0s - loss: 1.2911 - accuracy: 0.54 - ETA: 0s - loss: 1.2802 - accuracy: 0.55 - ETA: 0s - loss: 1.2701 - accuracy: 0.55 - ETA: 0s - loss: 1.2619 - accuracy: 0.55 - ETA: 0s - loss: 1.2549 - accuracy: 0.56 - ETA: 0s - loss: 1.2470 - accuracy: 0.56 - ETA: 0s - loss: 1.2340 - accuracy: 0.56 - ETA: 0s - loss: 1.2252 - accuracy: 0.57 - ETA: 0s - loss: 1.2183 - accuracy: 0.57 - ETA: 0s - loss: 1.2118 - accuracy: 0.57 - ETA: 0s - loss: 1.2060 - accuracy: 0.57 - ETA: 0s - loss: 1.1972 - accuracy: 0.58 - ETA: 0s - loss: 1.1890 - accuracy: 0.58 - ETA: 0s - loss: 1.1829 - accuracy: 0.58 - ETA: 0s - loss: 1.1786 - accuracy: 0.58 - ETA: 0s - loss: 1.1730 - accuracy: 0.58 - ETA: 0s - loss: 1.1674 - accuracy: 0.59 - ETA: 0s - loss: 1.1617 - accuracy: 0.59 - ETA: 0s - loss: 1.1569 - accuracy: 0.59 - ETA: 0s - loss: 1.1523 - accuracy: 0.59 - 2s 1ms/step - loss: 1.1508 - accuracy: 0.5974\n",
            "  1/313 [..............................] - ETA: 0s - loss: 0.8520 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0008s vs `on_test_batch_begin` time: 0.0074s). Check your callbacks.\n",
            "313/313 [==============================] - ETA: 10s - loss: 0.7408 - accuracy: 0.697 - ETA: 0s - loss: 0.7200 - accuracy: 0.761 - ETA: 0s - loss: 0.6997 - accuracy: 0.77 - ETA: 0s - loss: 0.7301 - accuracy: 0.75 - ETA: 0s - loss: 0.7267 - accuracy: 0.75 - ETA: 0s - loss: 0.7296 - accuracy: 0.75 - ETA: 0s - loss: 0.7292 - accuracy: 0.75 - ETA: 0s - loss: 0.7315 - accuracy: 0.75 - ETA: 0s - loss: 0.7296 - accuracy: 0.75 - 1s 2ms/step - loss: 0.7285 - accuracy: 0.7543\n",
            "--- Starting trial: run-4\n",
            "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'adam'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.4256 - accuracy: 0.18 - ETA: 1s - loss: 1.4829 - accuracy: 0.51 - ETA: 1s - loss: 1.2853 - accuracy: 0.57 - ETA: 1s - loss: 1.1417 - accuracy: 0.61 - ETA: 1s - loss: 1.0616 - accuracy: 0.64 - ETA: 1s - loss: 0.9953 - accuracy: 0.66 - ETA: 1s - loss: 0.9611 - accuracy: 0.67 - ETA: 1s - loss: 0.9268 - accuracy: 0.68 - ETA: 1s - loss: 0.8915 - accuracy: 0.69 - ETA: 1s - loss: 0.8672 - accuracy: 0.70 - ETA: 1s - loss: 0.8403 - accuracy: 0.71 - ETA: 1s - loss: 0.8150 - accuracy: 0.72 - ETA: 1s - loss: 0.7989 - accuracy: 0.72 - ETA: 1s - loss: 0.7814 - accuracy: 0.73 - ETA: 1s - loss: 0.7673 - accuracy: 0.73 - ETA: 1s - loss: 0.7541 - accuracy: 0.74 - ETA: 1s - loss: 0.7414 - accuracy: 0.74 - ETA: 1s - loss: 0.7318 - accuracy: 0.74 - ETA: 1s - loss: 0.7178 - accuracy: 0.75 - ETA: 0s - loss: 0.7081 - accuracy: 0.75 - ETA: 0s - loss: 0.6991 - accuracy: 0.75 - ETA: 0s - loss: 0.6915 - accuracy: 0.76 - ETA: 0s - loss: 0.6841 - accuracy: 0.76 - ETA: 0s - loss: 0.6771 - accuracy: 0.76 - ETA: 0s - loss: 0.6711 - accuracy: 0.76 - ETA: 0s - loss: 0.6655 - accuracy: 0.77 - ETA: 0s - loss: 0.6602 - accuracy: 0.77 - ETA: 0s - loss: 0.6575 - accuracy: 0.77 - ETA: 0s - loss: 0.6521 - accuracy: 0.77 - ETA: 0s - loss: 0.6456 - accuracy: 0.77 - ETA: 0s - loss: 0.6407 - accuracy: 0.77 - ETA: 0s - loss: 0.6353 - accuracy: 0.77 - ETA: 0s - loss: 0.6306 - accuracy: 0.78 - ETA: 0s - loss: 0.6260 - accuracy: 0.78 - ETA: 0s - loss: 0.6210 - accuracy: 0.78 - ETA: 0s - loss: 0.6162 - accuracy: 0.78 - ETA: 0s - loss: 0.6128 - accuracy: 0.78 - ETA: 0s - loss: 0.6084 - accuracy: 0.78 - 2s 1ms/step - loss: 0.6054 - accuracy: 0.7895\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.5668 - accuracy: 0.71 - ETA: 0s - loss: 0.4296 - accuracy: 0.85 - ETA: 0s - loss: 0.4588 - accuracy: 0.83 - ETA: 0s - loss: 0.4697 - accuracy: 0.83 - ETA: 0s - loss: 0.4648 - accuracy: 0.83 - 0s 672us/step - loss: 0.4634 - accuracy: 0.8329\n",
            "--- Starting trial: run-5\n",
            "{'num_units': 32, 'dropout': 0.1, 'optimizer': 'sgd'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.3371 - accuracy: 0.09 - ETA: 1s - loss: 1.9934 - accuracy: 0.30 - ETA: 1s - loss: 1.7724 - accuracy: 0.41 - ETA: 1s - loss: 1.6032 - accuracy: 0.47 - ETA: 1s - loss: 1.4786 - accuracy: 0.51 - ETA: 1s - loss: 1.3899 - accuracy: 0.54 - ETA: 1s - loss: 1.3192 - accuracy: 0.56 - ETA: 1s - loss: 1.2639 - accuracy: 0.57 - ETA: 0s - loss: 1.2189 - accuracy: 0.59 - ETA: 0s - loss: 1.1825 - accuracy: 0.60 - ETA: 0s - loss: 1.1506 - accuracy: 0.61 - ETA: 0s - loss: 1.1240 - accuracy: 0.61 - ETA: 0s - loss: 1.1026 - accuracy: 0.62 - ETA: 0s - loss: 1.0871 - accuracy: 0.62 - ETA: 0s - loss: 1.0678 - accuracy: 0.63 - ETA: 0s - loss: 1.0457 - accuracy: 0.64 - ETA: 0s - loss: 1.0266 - accuracy: 0.65 - ETA: 0s - loss: 1.0114 - accuracy: 0.65 - ETA: 0s - loss: 0.9993 - accuracy: 0.65 - ETA: 0s - loss: 0.9874 - accuracy: 0.66 - ETA: 0s - loss: 0.9786 - accuracy: 0.66 - ETA: 0s - loss: 0.9697 - accuracy: 0.66 - ETA: 0s - loss: 0.9605 - accuracy: 0.67 - ETA: 0s - loss: 0.9510 - accuracy: 0.67 - ETA: 0s - loss: 0.9421 - accuracy: 0.67 - ETA: 0s - loss: 0.9333 - accuracy: 0.68 - ETA: 0s - loss: 0.9258 - accuracy: 0.68 - ETA: 0s - loss: 0.9183 - accuracy: 0.68 - ETA: 0s - loss: 0.9098 - accuracy: 0.69 - ETA: 0s - loss: 0.9010 - accuracy: 0.69 - ETA: 0s - loss: 0.8922 - accuracy: 0.69 - 2s 882us/step - loss: 0.8922 - accuracy: 0.6962\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7151 - accuracy: 0.65 - ETA: 0s - loss: 0.6071 - accuracy: 0.78 - ETA: 0s - loss: 0.6361 - accuracy: 0.77 - ETA: 0s - loss: 0.6441 - accuracy: 0.77 - ETA: 0s - loss: 0.6418 - accuracy: 0.77 - 0s 734us/step - loss: 0.6416 - accuracy: 0.7770\n",
            "--- Starting trial: run-6\n",
            "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'adam'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.3709 - accuracy: 0.09 - ETA: 1s - loss: 1.6719 - accuracy: 0.42 - ETA: 1s - loss: 1.4013 - accuracy: 0.51 - ETA: 1s - loss: 1.2654 - accuracy: 0.56 - ETA: 1s - loss: 1.1507 - accuracy: 0.60 - ETA: 1s - loss: 1.0786 - accuracy: 0.62 - ETA: 1s - loss: 1.0322 - accuracy: 0.63 - ETA: 1s - loss: 1.0173 - accuracy: 0.64 - ETA: 1s - loss: 0.9860 - accuracy: 0.65 - ETA: 1s - loss: 0.9546 - accuracy: 0.66 - ETA: 1s - loss: 0.9273 - accuracy: 0.67 - ETA: 1s - loss: 0.9047 - accuracy: 0.68 - ETA: 1s - loss: 0.8829 - accuracy: 0.69 - ETA: 1s - loss: 0.8679 - accuracy: 0.69 - ETA: 1s - loss: 0.8527 - accuracy: 0.70 - ETA: 1s - loss: 0.8347 - accuracy: 0.70 - ETA: 1s - loss: 0.8204 - accuracy: 0.71 - ETA: 0s - loss: 0.8041 - accuracy: 0.71 - ETA: 0s - loss: 0.7919 - accuracy: 0.72 - ETA: 0s - loss: 0.7811 - accuracy: 0.72 - ETA: 0s - loss: 0.7706 - accuracy: 0.73 - ETA: 0s - loss: 0.7648 - accuracy: 0.73 - ETA: 0s - loss: 0.7571 - accuracy: 0.73 - ETA: 0s - loss: 0.7513 - accuracy: 0.73 - ETA: 0s - loss: 0.7455 - accuracy: 0.73 - ETA: 0s - loss: 0.7363 - accuracy: 0.74 - ETA: 0s - loss: 0.7306 - accuracy: 0.74 - ETA: 0s - loss: 0.7242 - accuracy: 0.74 - ETA: 0s - loss: 0.7166 - accuracy: 0.75 - ETA: 0s - loss: 0.7098 - accuracy: 0.75 - ETA: 0s - loss: 0.7033 - accuracy: 0.75 - ETA: 0s - loss: 0.6976 - accuracy: 0.75 - ETA: 0s - loss: 0.6921 - accuracy: 0.75 - ETA: 0s - loss: 0.6870 - accuracy: 0.75 - ETA: 0s - loss: 0.6822 - accuracy: 0.76 - ETA: 0s - loss: 0.6779 - accuracy: 0.76 - ETA: 0s - loss: 0.6728 - accuracy: 0.76 - ETA: 0s - loss: 0.6689 - accuracy: 0.76 - 2s 1ms/step - loss: 0.6681 - accuracy: 0.7662\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.5129 - accuracy: 0.81 - ETA: 0s - loss: 0.4447 - accuracy: 0.84 - ETA: 0s - loss: 0.4678 - accuracy: 0.83 - ETA: 0s - loss: 0.4734 - accuracy: 0.83 - ETA: 0s - loss: 0.4712 - accuracy: 0.82 - 0s 783us/step - loss: 0.4701 - accuracy: 0.8291\n",
            "--- Starting trial: run-7\n",
            "{'num_units': 32, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
            "1719/1719 [==============================] - ETA: 0s - loss: 2.7925 - accuracy: 0.03 - ETA: 4s - loss: 2.3261 - accuracy: 0.12 - ETA: 6s - loss: 2.2110 - accuracy: 0.21 - ETA: 11s - loss: 2.2045 - accuracy: 0.218 - ETA: 11s - loss: 2.1812 - accuracy: 0.233 - ETA: 9s - loss: 2.1039 - accuracy: 0.269 - ETA: 8s - loss: 2.0436 - accuracy: 0.30 - ETA: 6s - loss: 1.9434 - accuracy: 0.34 - ETA: 6s - loss: 1.8742 - accuracy: 0.37 - ETA: 6s - loss: 1.8488 - accuracy: 0.37 - ETA: 6s - loss: 1.8285 - accuracy: 0.38 - ETA: 6s - loss: 1.7800 - accuracy: 0.40 - ETA: 5s - loss: 1.6977 - accuracy: 0.43 - ETA: 4s - loss: 1.6265 - accuracy: 0.45 - ETA: 3s - loss: 1.5482 - accuracy: 0.48 - ETA: 3s - loss: 1.4923 - accuracy: 0.50 - ETA: 2s - loss: 1.4370 - accuracy: 0.51 - ETA: 2s - loss: 1.3820 - accuracy: 0.53 - ETA: 2s - loss: 1.3373 - accuracy: 0.54 - ETA: 1s - loss: 1.2975 - accuracy: 0.55 - ETA: 1s - loss: 1.2582 - accuracy: 0.57 - ETA: 1s - loss: 1.2314 - accuracy: 0.57 - ETA: 1s - loss: 1.2049 - accuracy: 0.58 - ETA: 1s - loss: 1.1818 - accuracy: 0.59 - ETA: 1s - loss: 1.1583 - accuracy: 0.60 - ETA: 1s - loss: 1.1415 - accuracy: 0.61 - ETA: 0s - loss: 1.1225 - accuracy: 0.61 - ETA: 0s - loss: 1.1052 - accuracy: 0.62 - ETA: 0s - loss: 1.0883 - accuracy: 0.62 - ETA: 0s - loss: 1.0733 - accuracy: 0.63 - ETA: 0s - loss: 1.0555 - accuracy: 0.63 - ETA: 0s - loss: 1.0423 - accuracy: 0.64 - ETA: 0s - loss: 1.0307 - accuracy: 0.64 - ETA: 0s - loss: 1.0199 - accuracy: 0.65 - ETA: 0s - loss: 1.0093 - accuracy: 0.65 - ETA: 0s - loss: 0.9990 - accuracy: 0.65 - ETA: 0s - loss: 0.9881 - accuracy: 0.66 - 2s 1ms/step - loss: 0.9841 - accuracy: 0.6634\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.7530 - accuracy: 0.62 - ETA: 0s - loss: 0.6295 - accuracy: 0.78 - ETA: 0s - loss: 0.6580 - accuracy: 0.77 - ETA: 0s - loss: 0.6577 - accuracy: 0.76 - 0s 580us/step - loss: 0.6546 - accuracy: 0.7698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbJjyMBmJXZv",
        "outputId": "49aee524-3a66-46e4-9dcd-3fefeef62642"
      },
      "source": [
        "#The HParams dashboard can now be opened. Start TensorBoard and click on \"HParams\" at the top.\n",
        "%tensorboard --logdir logs/hparam_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-4942d2664b697da7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-4942d2664b697da7\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9hGsky5jwNY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}