{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SIT_W2D2_HT2_Model_Development.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmAchieng/DataSciencePracticeSeries/blob/master/MLEngineering_Model_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of3HGFCW2ii7"
      },
      "source": [
        "<a id='Q0'></a>\n",
        "<center><a target=\"_blank\" href=\"http://www.propulsion.academy\"><img src=\"https://drive.google.com/uc?id=1McNxpNrSwfqu1w-QtlOmPSmfULvkkMQV\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "<center> <h4 style=\"color:#303030\"> Applied Machine Learning: </h4> </center>\n",
        "<center> <h1 style=\"color:#303030\">Predict House Value using neighboorhood characteristics</h1> </center>\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "<center style=\"color:#303030\"><h4>Propulsion Academy, 2021</h4></center>\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "<div style=\"background:#EEEDF5;border-top:0.1cm solid #EF475B;border-bottom:0.1cm solid #EF475B;\">\n",
        "    <div style=\"margin-left: 0.5cm;margin-top: 0.5cm;margin-bottom: 0.5cm\">\n",
        "        <p><strong>Goal:</strong>Implement Experiment tracking on a Regression problem using real estate data</p>\n",
        "        \n",
        "</div>\n",
        "\n",
        "<nav style=\"text-align:right\"><strong>\n",
        "        <a style=\"color:#00BAE5\" href=\"https://monolith.propulsion-home.ch/backend/api/momentum/materials/intro-2-ds-materials/index.html\" title=\"momentum\"> Introduction to Data Science</a>|\n",
        "        <a style=\"color:#00BAE5\" href=\"https://monolith.propulsion-home.ch/backend/api/momentum/materials/intro-2-ds-materials/weeks/week2/day2/index.html\" title=\"momentum\">Machine Learning Engineering</a>|\n",
        "        <a style=\"color:#00BAE5\" href=\"https://colab.research.google.com/drive/15Ehfd97f7yTft_GT3GXsz3ZDSDS_dGYf?usp=sharing\" title=\"momentum\">  California House Price Training</a>\n",
        "</strong></nav>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4evWISCtJkE"
      },
      "source": [
        "This notebook showcases a minimal implementation of training a machine learning model, with logging, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckLGGhLpmYD8"
      },
      "source": [
        "<a id='SU' name=\"SU\"></a>\n",
        "## [Set up](#P0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k51LlYS27Bql"
      },
      "source": [
        "### package install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLmr1n_tX283"
      },
      "source": [
        "Please note you **need to restart the run after the installation** for it to take effect!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTC_OuUpBXlC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2f1280-dad0-44ea-e19e-9a3897534a99"
      },
      "source": [
        "!sudo apt-get install build-essential swig\n",
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install\n",
        "!pip install auto-sklearn\n",
        "!pip install pipelineprofiler # visualize the pipelines created by auto-sklearn\n",
        "!pip install shap\n",
        "!pip install --upgrade plotly\n",
        "!pip3 install -U scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,271 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   209  100   209    0     0   3603      0 --:--:-- --:--:-- --:--:--  3603\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.14.1) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Collecting scikit-learn<0.25.0,>=0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.24.0) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.24.0) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.24.0) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.1 threadpoolctl-2.1.0\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting distributed>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/b0/3454dc44239c526f9c9e4cf04f62823776b71f927db74302986d56e7a9a1/distributed-2021.4.0-py3-none-any.whl (684kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (3.13)\n",
            "Collecting dask>=2021.03.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/34/a4f8808336840f7bc3880fef3a4562cb4bc89c9cc90026646fa3d51526cd/dask-2021.4.0-py3-none-any.whl (941kB)\n",
            "\u001b[K     |████████████████████████████████| 942kB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (2.3.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (0.11.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (54.2.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (1.0.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (2.0.0)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (5.1.1)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0) (5.4.8)\n",
            "Collecting fsspec>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/11/f7689b996f85e45f718745c899f6747ee5edb4878cadac0a41ab146828fa/fsspec-0.9.0-py3-none-any.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 42.0MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.2.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0->dask>=2021.03.0->distributed>=2.2.0) (3.8.1)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0->dask>=2021.03.0->distributed>=2.2.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0->dask>=2021.03.0->distributed>=2.2.0) (3.7.4.3)\n",
            "Installing collected packages: cloudpickle, fsspec, locket, partd, dask, distributed\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed cloudpickle-1.6.0 dask-2021.4.0 distributed-2021.4.0 fsspec-0.9.0 locket-0.2.1 partd-1.2.0\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0) (1.15.0)\n",
            "Collecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/43/73944aa5ad2b3185c0f0ba0ee6f73277f2eb51782ca6ccf3e6793caf209a/liac-arff-2.5.0.tar.gz\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-cp37-none-any.whl size=11732 sha256=53bf5c1d422cfe7dc6b1e4ecc223176eff44d04490ea678ae4c9b44ca20a9dcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/8d/b4/8bfce5beea9a3496cc15b24961876adb7b6e2912ff09164179\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.5.0\n",
            "Collecting ConfigSpace<0.5,>=0.4.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c3/3c21e8d82a639fd821f538e6d7f830b654a6ce1fe52644be1a67f323f707/ConfigSpace-0.4.18.tar.gz (950kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 4.3MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14) (0.29.22)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14) (2.4.7)\n",
            "Building wheels for collected packages: ConfigSpace\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9clsCHvKExn"
      },
      "source": [
        "### Packages imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN_lTQboKExo"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "from sklearn import set_config\n",
        "from sklearn.pipeline import Pipeline\n",
        "from pandas_profiling import ProfileReport\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import autosklearn.regression\n",
        "import PipelineProfiler\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from joblib import dump\n",
        "\n",
        "import shap\n",
        "\n",
        "import datetime\n",
        "\n",
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B-eWIFB579h"
      },
      "source": [
        "### Google Drive connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAo_4yUyT_H_"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh7ljdZY7X8Y"
      },
      "source": [
        "### options and settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4iSfOb_alvK"
      },
      "source": [
        "data_path = \"/content/drive/MyDrive/Introduction2DataScience/tutorials/w2d2/data/raw/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt69wghpd0cr"
      },
      "source": [
        "model_path = \"/content/drive/MyDrive/Introduction2DataScience/tutorials/w2d2/models/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q70rbi-qjhrl"
      },
      "source": [
        "timesstr = str(datetime.datetime.now()).replace(' ', '_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-hJtx7Llov8"
      },
      "source": [
        "logging.basicConfig(filename=f\"{model_path}explog_{timesstr}.log\", level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiBsfiFvstdj"
      },
      "source": [
        "Please Download the data from [this source](https://drive.google.com/file/d/1MUZrfW214Pv9p5cNjNNEEosiruIlLUXz/view?usp=sharing), and upload it on your Introduction2DataScience/data google drive folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNXnzMwM7w5v"
      },
      "source": [
        "<a id='P1' name=\"P1\"></a>\n",
        "## [Loading Data and Train-Test Split](#P0)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjXNgfq7_AOA"
      },
      "source": [
        "df = pd.read_csv(f'{data_path}california_housing.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Qa2jk6Ap5M"
      },
      "source": [
        "test_size = 0.2\n",
        "random_state = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4N_8ygZnBDh"
      },
      "source": [
        "train, test = train_test_split(df, test_size=test_size, random_state=random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8BYeJFwl-x3"
      },
      "source": [
        "logging.info(f'train test split with test_size={test_size} and random state={random_state}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19fyLTMjA3AK"
      },
      "source": [
        "train.to_csv(f'{data_path}CaliforniaTrain.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eQ3o0Ba8AgX"
      },
      "source": [
        "train= train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HASCUWGHA6-y"
      },
      "source": [
        "test.to_csv(f'{data_path}CaliforniaTest.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe_rggZ58Dt2"
      },
      "source": [
        "test = test.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4WEfNY7qqMo"
      },
      "source": [
        "<a id='P2' name=\"P2\"></a>\n",
        "## [Modelling](#P0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YWzJPYbEl7-"
      },
      "source": [
        "X_train, y_train = train.iloc[:,:-1], train.iloc[:,-1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XABH09h1mb8u"
      },
      "source": [
        "total_time = 600\n",
        "per_run_time_limit = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEYQB36DkhGN"
      },
      "source": [
        "automl = autosklearn.regression.AutoSklearnRegressor(\n",
        "    time_left_for_this_task=total_time,\n",
        "    per_run_time_limit=per_run_time_limit,\n",
        ")\n",
        "automl.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6QBz7cWmm6i"
      },
      "source": [
        "logging.info(f'Ran autosklearn regressor for a total time of {total_time} seconds, with a maximum of {per_run_time_limit} seconds per model run')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWZfqnwVdmWV"
      },
      "source": [
        "dump(automl, f'{model_path}model{timesstr}.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMYvVLrBnFE4"
      },
      "source": [
        "logging.info(f'Saved regressor model at {model_path}model{timesstr}.pkl ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKpVBmU6ldhY"
      },
      "source": [
        "logging.info(f'autosklearn model statistics:')\n",
        "logging.info(automl.sprint_statistics())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d18JiayFbrf4"
      },
      "source": [
        "#profiler_data= PipelineProfiler.import_autosklearn(automl)\n",
        "#PipelineProfiler.plot_pipeline_matrix(profiler_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz9Nu9Lgb7oJ"
      },
      "source": [
        "<a id='P2' name=\"P2\"></a>\n",
        "## [Model Evluation and Explainability](#P0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFqCOQRkT9IG"
      },
      "source": [
        "Let's separate our test dataframe into a feature variable (X_test), and a target variable (y_test):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI3Jblr6E0Ti"
      },
      "source": [
        "X_test, y_test = test.iloc[:,:-1], test.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAd7sBy5FPZk"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3FY_CN2UJ3Z"
      },
      "source": [
        "Now, we can attempt to predict the median house value from our test set. To do that, we just use the .predict method on the object \"automl\" that we created and trained in the last sections:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZSB-vsr_n4c"
      },
      "source": [
        "y_pred = automl.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ayqqJU9UaGn"
      },
      "source": [
        "Let's now evaluate it using the mean_squared_error function from scikit learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9SPyU27b7oJ"
      },
      "source": [
        "logging.info(f\"Mean Squared Error is {mean_squared_error(y_test, y_pred)}, \\n R2 score is {automl.score(X_test, y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcrrUloxU7B4"
      },
      "source": [
        "we can also plot the y_test vs y_pred scatter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFCwsABoofEw"
      },
      "source": [
        "df = pd.DataFrame(np.concatenate((X_test, y_test.to_numpy().reshape(-1,1), y_pred.reshape(-1,1)),  axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y11JqR-XoxOf"
      },
      "source": [
        "df.columns = ['longitude', 'latitude', 'housing_median_age', 'households',\n",
        "               'median_income', 'bedroom_per_room',\n",
        "               'rooms_per_household', 'population_per_household', 'True Target', 'Predicted Target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UzcbD0pYmwY"
      },
      "source": [
        "fig = px.scatter(df, x='Predicted Target', y='True Target')\n",
        "fig.write_html(f\"{model_path}residualfig_{timesstr}.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O526-nR3onur"
      },
      "source": [
        "logging.info(f\"Figure of residuals saved as {model_path}residualfig_{timesstr}.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMYUVvYbFUFP"
      },
      "source": [
        "#### Model Explainability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v60Ykm7U1A9u"
      },
      "source": [
        "explainer = shap.KernelExplainer(model = automl.predict, data = X_test.iloc[:50, :], link = \"identity\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-SbpmsB2SE_"
      },
      "source": [
        "# Set the index of the specific example to explain\n",
        "X_idx = 0\n",
        "shap_value_single = explainer.shap_values(X = X_test.iloc[X_idx:X_idx+1,:], nsamples = 100)\n",
        "X_test.iloc[X_idx:X_idx+1,:]\n",
        "# print the JS visualization code to the notebook\n",
        "shap.initjs()\n",
        "shap.force_plot(base_value = explainer.expected_value,\n",
        "                shap_values = shap_value_single,\n",
        "                features = X_test.iloc[X_idx:X_idx+1,:], \n",
        "                show=False,\n",
        "                matplotlib=True\n",
        "                )\n",
        "plt.savefig(f\"{model_path}shap_example_{timesstr}.png\")\n",
        "logging.info(f\"Shapley example saved as {model_path}shap_example_{timesstr}.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV5Vt2k-2l1P"
      },
      "source": [
        "shap_values = explainer.shap_values(X = X_test.iloc[0:50,:], nsamples = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r60XylOsOZRN"
      },
      "source": [
        "# print the JS visualization code to the notebook\n",
        "shap.initjs()\n",
        "fig = shap.summary_plot(shap_values = shap_values,\n",
        "                  features = X_test.iloc[0:50,:],\n",
        "                  show=False)\n",
        "plt.savefig(f\"{model_path}shap_summary_{timesstr}.png\")\n",
        "logging.info(f\"Shapley summary saved as {model_path}shap_summary_{timesstr}.png\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}